sparkta {

  api {
    host = 0.0.0.0
    port = 9090
  }

  swagger {
    host = 0.0.0.0
    port = 9091
  }

  config {
    executionMode = local
    rememberPartitioner = true
    stopGracefully = true
  }

  local {
    spark.app.name = SPARKTA
    spark.master = "local[*]"
    spark.executor.memory = 1024m
    spark.app.name = SPARKTA
    spark.sql.parquet.binaryAsString = true
    spark.streaming.concurrentJobs = 1
    #spark.metrics.conf = /opt/sds/sparkta/benchmark/src/main/resources/metrics.properties
  }

  hdfs {
    hadoopUserName = stratio
    hadoopConfDir = /home/user
    hdfsMaster = hdfsmaster
    pluginsFolder = "jars"
    executionJarFolder = "jarDriver"
    classpathFolder = "classpath"
  }

  mesos {
    sparkHome = ""
    deployMode = cluster
    numExecutors = 2
    masterDispatchers = 127.0.0.1
    spark.app.name = SPARKTA
    spark.streaming.concurrentJobs = 1
    spark.cores.max = 2
    spark.mesos.extra.cores = 1
    spark.mesos.coarse = true
    spark.executor.memory = 2G
    spark.driver.cores = 1
    spark.driver.memory= 2G
    #spark.metrics.conf = /opt/sds/sparkta/benchmark/src/main/resources/metrics.properties
  }

  yarn {
    sparkHome = ""
    master = yarn-cluster
    numExecutors = 2
    executorMemory = 2G
    executorCores = 2
    spark.app.name = SPARKTA
    #spark.metrics.conf = /opt/sds/sparkta/benchmark/src/main/resources/metrics.properties
  }

  standAlone {
    sparkHome = ""
    spark.app.name = SPARKTA
    #spark.metrics.conf = /opt/sds/sparkta/benchmark/src/main/resources/metrics.properties
  }

  zk {
    connectionString = "localhost:2181"
    connectionTimeout = 15000
    sessionTimeout = 60000
    retryAttempts = 5
    retryInterval = 10000
  }

  akka {
    controllerActorInstances = 5
    streamingActorInstances = 3
  }

}